\chapter{Methodology/Design/Implementation}
\label{chapter:method}
\section{Phase Locked Loop System Overview}
\label{sec:pll_overview}
A Phase-Locked Loop (PLL) is a negative feedback control system circuit. As the name implies, the purpose of a PLL is to generate a signal whose phase matches that of a reference signal. This is achieved through multiple iterations of comparing the reference and feedback signals (ref fig:\ref{fig:pll_1}). The overall goal of the PLL is to align the phases of the reference and feedback signals—this is referred to as the lock mode. Once locked, the PLL continues to compare the two signals, but since they are in lock mode, the PLL output remains constant. \\
\textbf{A basic PLL consists of four main components:}
\begin{enumerate}
	\item Phase Detector or Phase Frequency Detector (PD or PFD)
	\item Charge Pump (CP)
	\item Low Pass Filter (LPF)
	\item Voltage-Controlled Oscillator (VCO)
\end{enumerate}
The Phase Frequency Detector (PFD) measures the phase difference between the reference and feedback signals. If a phase difference exists, it generates synchronized “up” or “down” signals to the charge pump and low pass filter. If the error signal from the PFD is an “up” signal, the charge pump adds charge to the LPF capacitor, increasing the control voltage, \( V_{\text{cntrl}} \). Conversely, if the error signal is a “down” signal, the charge pump removes charge from the LPF capacitor, decreasing \( V_{\text{cntrl}} \).\input{figs/pll_block.tex}\\
The control voltage \( V_{\text{cntrl}} \) serves as the input to the VCO. The LPF is essential for allowing only DC signals into the VCO and for storing the charge from the CP. The VCO adjusts the feedback signal's frequency based on the error generated by the PFD. If the PFD generates an “up” signal, the VCO speeds up the feedback signal. Conversely, if a “down” signal is generated, the VCO slows it down. The output of the VCO is then fed back to the PFD to recalculate the phase difference, thereby creating a closed-loop frequency control system.

\subsection{Phase Detector}
A phase detector is a circuit that detects the difference in phase between its two input
signals. An example of a basic phase detector is the XOR gate. It produces error pulses on both
falling and rising edges.
\input{figs/xor_pd.tex}
\subsubsection{Phase Frequency Detector}
A phase frequency detector (PFD) is a circuit that detects the difference in phase and frequency between its two input signals. The PFD is a more advanced version of the basic phase detector. It can detect both phase and frequency differences, making it more suitable for applications where the input signals may have different frequencies. The PFD generates an error signal that is proportional to the phase and frequency difference between the two input signals. This error signal is then used to control the charge pump and low pass filter in the PLL.
\input{figs/pfd_block.tex}
\subsection{Nanda biceps Pump}
The charge pump is a circuit that converts the error signal from the phase detector into a control voltage for the VCO. The charge pump consists of two switches and a capacitor. The switches are controlled by the error signal from the phase detector. When the error signal is high, the switch connects the capacitor to the power supply, charging it. When the error signal is low, the switch connects the capacitor to ground, discharging it. The control voltage for the VCO is taken from the capacitor.
\input{figs/cp_block.tex}
\subsection{Low Pass Filter}
The low pass filter is a circuit that removes high frequency noise from the control voltage generated by the charge pump. The low pass filter consists of a resistor and a capacitor. The resistor limits the current flowing into the capacitor, while the capacitor stores the charge. The output of the low pass filter is a smooth control voltage that is fed to the VCO.
% \input{figs/lpf.tex}
\subsection{Voltage Controlled Oscillator}
The voltage controlled oscillator (VCO) is a circuit that generates an output signal whose frequency is proportional to the control voltage. The VCO consists of a transistor and a capacitor. The transistor is biased by the control voltage, which determines its operating frequency. The output of the VCO is fed back to the phase detector to complete the PLL loop.
\begin{equation}
	\label{eq:vco_char}
	f_{out} = K_{vco} * V_{in} + f_{min}
\end{equation}
\input{figs/vco_block.tex}
The VCO transfer function can be given as
\begin{equation}
	\label{eq:vco_tf}
	H_{vco}(s) = \frac{\phi_{o}(s)}{v_{o}(s)} = \frac{K_{vco}}{S}
\end{equation}
The gain of the voltage-controlled oscillator is simply the slope of the curves given in Fig.\ref{fig:vco_block}. This gain can be written as
\begin{equation}
	\label{eq:vco_gain}
	K_{vco} = 2\pi  * \frac{f_{max} - f_{min}}{V_{max} - V_{min}}(radians/s * V)
\end{equation}
Kvco is an important factor it Determines the PLL settling time.
There are different types of VCO like : Cross Coupled LC VCO, Current Starved VCO, Colpitts Oscillator. For this project, Current Starved VCO is used.
\subsection{Frequency Divider}
The frequency divider is a circuit that divides the frequency of the output signal from the VCO by a fixed integer value. The frequency divider is used to reduce the frequency of the output signal to match the frequency of the reference signal. The frequency divider can be implemented using a flip-flop or a counter. The output of the frequency divider is fed back to the phase detector to complete the PLL loop.
\subsubsection*{Frequency Divider Principle}
A frequency divider works by toggling the output state of a flip-flop at each rising (positive) edge of the input clock signal. A single flip-flop divides the frequency of the input clock by a factor of 2. Cascading multiple flip-flops results in further division:
\[
f_{\text{out}} = \frac{f_{\text{in}}}{2^n}
\]
Where:
\begin{itemize}
    \item $f_{\text{in}}$ is the input clock frequency,
    \item $f_{\text{out}}$ is the output frequency after division,
    \item $n$ is the number of flip-flops connected in series.
\end{itemize}
\subsubsection*{Positive Edge-Triggered Flip-Flop}
A positive edge-triggered flip-flop changes its output state only at the rising edge of the clock signal. A T (toggle) flip-flop toggles its output on each clock edge. However, a D flip-flop can be configured to behave as a T flip-flop by connecting the inverted output back to the input:
\[
D = \sim Q
\]
This ensures the flip-flop toggles its output on each positive clock edge.
\subsubsection*{Implementation Using Pass Gates and Inverters}
A D flip-flop can be constructed using two D latches in a master-slave configuration, controlled by a clock and its complement. Each latch consists of pass gates and inverters.
\begin{itemize}
    \item Pass gates (transmission gates) are used to control the flow of data based on the clock signal. They are bidirectional switches typically made using a combination of NMOS and PMOS transistors.
    \item Inverters act as buffers and memory elements to store and propagate the logic state.
\end{itemize}
\subsubsection*{Frequency Division Design Circuit Using LT Spice}

\subsubsection*{Positive Edge-Triggered Flip-Flop}
A positive edge-triggered flip-flop changes its output state only at the rising edge of the clock signal. A T (toggle) flip-flop toggles its output on each clock edge. However, a D flip-flop can be configured to behave as a T flip-flop by connecting the inverted output back to the input:
\[
D = \sim Q
\]
This ensures the flip-flop toggles its output on each positive clock edge.
\subsubsection*{Implementation Using Pass Gates and Inverters}
A D flip-flop can be constructed using two D latches in a master-slave configuration, controlled by a clock and its complement. Each latch consists of pass gates and inverters.
\begin{itemize}
    \item Pass gates (transmission gates) are used to control the flow of data based on the clock signal. They are bidirectional switches typically made using a combination of NMOS and PMOS transistors.
    \item Inverters act as buffers and memory elements to store and propagate the logic state.
\end{itemize}
\subsubsection*{Frequency Division Design Circuit Using LT Spice}
To design a frequency divider circuit in LT Spice, follow these steps:
\begin{itemize}
    \item Create a schematic with a clock source and a D flip-flop.
    \item Configure the D flip-flop to toggle on each clock edge by connecting its inverted output back to the input.
    \item Simulate the circuit to observe the frequency division at the output.
    \item For cascading, connect the output of one flip-flop to the clock input of the next stage.
\end{itemize}
\subsubsection*{Working Principle}
\begin{itemize}
    \item When CLK = 1, the master latch is transparent and allows input data to propagate, while the slave latch holds its state.
    \item When CLK = 0, the master latch latches the input data, and the slave latch becomes transparent to pass the stored value to the output.
    \item This configuration ensures that data is transferred to the output only on the rising edge of the clock, making it a positive edge-triggered flip-flop.
\end{itemize}
\subsubsection*{Frequency Division Operation}
By cascading multiple such flip-flops, a frequency divider circuit is realized. The output of each flip-flop acts as the clock for the next stage. Since each stage toggles at half the frequency of the previous one, the overall division factor is \(2^n\).

For example:
\begin{itemize}
    \item 1 Flip-Flop → Divide by 2
    \item 2 Flip-Flops → Divide by 4
    \item 3 Flip-Flops → Divide by 8
\end{itemize}
\begin{figure}[H] % Use 'H' specifier for strict placement
    \centering
    \includegraphics[width=0.8\textwidth]{figs/circuit.png}
    \caption{Frequency Divider Circuit}
    \label{fig:LT Spice Circuit}
\end{figure}
The schematic shown in the figure represents a frequency divider circuit designed using positive edge-triggered D flip-flops. The circuit is implemented at the transistor level using pass gates (transmission gates) and inverters, which are fundamental components in CMOS logic design. This implementation provides a realistic view of how sequential circuits function at a lower abstraction level, offering better understanding of timing, logic flow, and hardware behavior.
The design uses a PULSE voltage source to generate the clock signal. This source is defined to oscillate between 0V and 1.8V with 1 ns rise and fall times, a pulse width of 100 ns, and a time period of 300 ns. The generated clock signal (clk) is used to drive the flip-flops in the circuit. An inverter is used to create the complementary clock signal (clk\_b), which is necessary to properly control the pass gates in the master-slave latch configuration of each D flip-flop.

Each flip-flop is constructed using two D latches connected in a master-slave configuration. Each latch consists of a pair of transmission gates, controlled by the clock and its complement, and inverters, which serve to store and propagate the logic state. This structure ensures that the flip-flop captures input data only on the rising edge of the clock signal, making it a positive edge-triggered flip-flop. To make the flip-flops function as T (toggle) flip-flops, the inverted output (\(Q_b\)) is fed back to the D input of each flip-flop. This feedback ensures that the flip-flop toggles its output on every rising edge of the clock.

In this circuit, two flip-flops are cascaded to form a 2-stage frequency divider. The first flip-flop toggles its output on every clock cycle, effectively dividing the input frequency by 2. The second flip-flop receives the output of the first as its clock input and toggles on every rising edge of that signal, thereby dividing the frequency by another factor of 2. As a result, the final output signal has a frequency equal to one-fourth of the original input clock. This cascading approach can be extended to more stages for greater frequency division.

The simulation is performed using SPICE, with the \texttt{.tran 100u} command specifying a transient analysis over a period of 100 microseconds to observe the dynamic behavior of the circuit. The schematic also includes a reference to a process design kit (\texttt{.INCLUDE tsmc018.lib}), which models the behavior of transistors based on the TSMC 180nm CMOS technology. This provides accurate transistor-level simulation results, allowing verification of correct operation and timing characteristics.

In conclusion, the schematic demonstrates the design and working of a CMOS-based frequency divider using positive edge-triggered D flip-flops implemented with pass gates and inverters. It effectively divides the clock frequency by powers of two and can be used in a variety of digital systems requiring timing control, clock scaling, or counter functionality.

\begin{figure}[H] % Use 'H' specifier for strict placement
    \centering
    \includegraphics[width=0.8\textwidth]{figs/waveform.png}
    \caption{Frequency Divider Output Waveform}
    \label{fig:Output Waveform}
\end{figure}
\subsubsection*{Conclusion}
In this project, a frequency divider circuit was successfully designed and implemented using positive edge-triggered D flip-flops constructed with pass gates and inverters. The use of transistor-level design under TSMC 180nm CMOS technology provided a deeper understanding of the internal working of sequential circuits. Simulation results verified that each flip-flop stage effectively divides the input clock frequency by a factor of two. This design is efficient for low-power, high-speed digital systems and demonstrates the practical use of basic building blocks in creating complex timing circuits.

\subsubsection*{Applications}
\begin{itemize}
    \item \textbf{Clock Division in Microprocessors:} Used to generate lower frequency clocks from a high-speed master clock.
    \item \textbf{Digital Watches and Timers:} Essential for time base generation.
    \item \textbf{Pulse Generation Circuits:} Helps in creating precise timing pulses for control systems.
    \item \textbf{Frequency Synthesizers:} Used in communication systems to derive required frequencies.
\end{itemize}
\subsection{Charge Pump Design}
\subsection{Low Pass Filter Design}
\subsection{Voltage Controlled Oscillator Design}
In this section the Design of VCO has been shown.We have choosen current starved VCO for our design. The current starved VCO is a type of voltage-controlled oscillator (VCO) that uses a current source to control the frequency of oscillation. The basic idea behind the current starved VCO is to use a current source to control the charging and discharging of a capacitor, which in turn determines the frequency of oscillation. The current starved VCO is widely used in PLL circuits because it is simple to implement and can be easily integrated into CMOS technology.
The VCO should be Linear in a particular Operating region. The PLL built in this project will be of of the application 1GHz


% \includegraphics[0.6\textwidth]{figs/cs_vco_design.png}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{figs/cs_vco_design.png}
	% \vspace{-0.3cm}
	\caption{Current Starved VCO Design}
	\label{fig:cs_vco_design}
	\vspace{0.5cm}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{figs/vco_simplified.png}
	% \vspace{-0.3cm}
	\caption{Simplified view of a single stage of the current-starved VCO}
	\label{fig:vco_simplified}
\end{figure}

To determine the design equations for use with the current-starved VCO, consider
the simplified schematic of one stage of the VCO fig \ref{fig:vco_simplified}. The total
capacitance on the drains of M2 and M3 is given by
\begin{equation}
	C_{\text{total}} = C_{\text{out}} + C_{\text{in}} = 
\underbrace{C'_{\text{ox}}(W_p L_p + W_n L_n)}_{\text{C\textsubscript{out}}} + 
\underbrace{\frac{3}{2} C'_{\text{ox}}(W_p L_p + W_n L_n)}_{\text{C\textsubscript{in}}}
\end{equation}
which is simply the output and input capacitances of the inverter. This equation can be written in a more useful form as
\begin{equation}
C_{\text{tot}} = \frac{5}{2} C'_{\text{ox}} (W_p L_p + W_n L_n)
\tag{19.19}
\end{equation}

\noindent The time it takes to charge $C_{\text{total}}$ from zero to $V_{SP}$ with the constant-current $I_{D4}$ is given by
\begin{equation}
t_1 = C_{\text{tot}} \cdot \frac{V_{SP}}{I_{D4}}
\tag{19.20}
\end{equation}

\noindent while the time it takes to discharge $C_{\text{total}}$ from $V_{DD}$ to $V_{SP}$ is given by
\begin{equation}
t_2 = C_{\text{tot}} \cdot \frac{V_{DD} - V_{SP}}{I_{D1}}
\tag{19.21}
\end{equation}

If we set $I_{D4} = I_{D1} = I_D$ (which we will label $I_{\text{Dcenter}}$ when $V_{\text{inVCO}} = V_{DD}/2$), then the sum of $t_1$ and $t_2$ is simply
\begin{equation}
t_1 + t_2 = \frac{C_{\text{tot}} \cdot V_{DD}}{I_D}
\tag{19.22}
\end{equation}

The oscillation frequency of the current-starved VCO for $N$ (an odd number $\geq 5$) of stages is
\begin{equation}
f_{\text{osc}} = \frac{1}{N(t_1 + t_2)} = \frac{I_D}{N \cdot C_{\text{tot}} \cdot V_{DD}}
\tag{19.23}
\end{equation}

which is $f_{\text{center}}(@ V_{\text{inVCO}} = V_{DD}/2 \text{ and } I_D = I_{\text{Dcenter}})$

firstly we have designed the Inverter stages and sized them accordingly and cascaded them to our required and connected a current Mirror to all the stages as in the Fig \ref{fig:vco_circuit}. The current mirror is used to control the current flowing through the inverter stages and thus control the frequency of oscillation. The output of the VCO is taken from the output of the last inverter stage. The VCO is designed to operate at a frequency of 1 GHz.
\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\textwidth]{figs/vco_c.png}
	% \vspace{-0.3cm}
	\caption{Current Starved VCO Circuit}
	\label{fig:vco_circuit}
	\vspace{0.5cm}
\end{figure}\\
The VCO ouput is not inherently a square wave (refer fig:\ref{fig:vco_op_c}) due to non-Ideal charachteristic of inverter here the ouput of the VCO is a irregular triangular wave. The output of the VCO is fed to a buffer and an inverter to convert the  of triangular wave to a square wave.
\begin{figure}
	\centering
	\includegraphics[width=0.9\textwidth]{figs/vco_op_both.png}
	% \vspace{-0.3cm}
	\caption{VCO output waveform before and after buffer+inverter}
	\label{fig:vco_op_c}
	\vspace{0.5cm}
\end{figure}
In Figure \ref{fig:vco_sim}, the Transient analysis of circuit in Figure \ref{fig:vco_circuit} is shown.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{figs/vco_op1.png}
	% \vspace{-0.3cm}
	\caption{output waveform of VCO}
	\label{fig:vco_sim}
\end{figure}


% \begin

% \subsection{LSTM network}

% \begin{figure*}[t]
% 	\centering
% 	\includegraphics[ width=\textwidth]{figs/LSTM_network.png}
% 	\vspace{-0.5cm}
% 	\caption{Structure of the proposed LSTM network}
% 	\label{fig:LSTM_network}
% 	\vspace{0.5cm}
% \end{figure*}

% Consider a video as a sequence of image frames i.e. $V = I_{0},I_{1},...,I_{n}$ where $I_{k}$ s a matrix of fixed dimensions. Given detections $D = D_{0},D_{1},...,D_{n}$, for the objects present in each frame , where each  is a list of bounding box locations, class predictions, and other information corresponding to objects contained in the image , our goal here is to estimate the bounding box coordinates $B_{k+1,i}$ for each object in the following frame; $I_{k+1}$. Note that  $B_{k,i} = (x_{k,i},y_{k,i},h_{k,i},w_{k,i})$ where $x,y,h,w$ correspond to $x,y$ co-ordinates of centre, height and width of the bounding box for the $i^{th}$ object in the $k^{th}$ frame. Further, this system would operate in an online setting where at any given instance when time $t = k$, the frames, hence detections too are present only up to $I_{k}$ and $D_{k}$ respectively. Further the $i^{th}$ object will be consistent across consecutive frames (obtained using the output of the system) until the object disappears. The LSTM component can be viewed as a function $L$ with $L(D_{0},D_{1},...,D_{k}) = F_{k}$ where $F_{k}$ is a list of temporally aware feature maps $F_{k,i}$ corresponding to each object $i$ present within $D_{k}$. The remaining two functions; $C$ and $R$ correspond to classification (selecting anchor) and regression (estimating deviation from anchor) of the exact bounding box targets. Each bounding box datum $(x,y,h,w)$ is interpreted as a deviation from the previous time step $(\dot{x},\dot{y},\dot{h},\dot{w})$ which reduces the mean of those variables. Note that due to the discrete nature of data, $\dot{x} = x - x_{i-1}$ Using normalized co-ordinates ($x,y,h,w$ values divided by relevant image dimensions); this range will be within $(-1, 1)$ and an optimum number of anchors can be used to estimate this value as a classification problem. 
% \par Having laid down the classifications on to the targets, the required estimates from the classification function would be a one hot encoded tensor; $C_{out}$ of shape $(P, 4)$ for $P$ bins of anchors and 4 bounding box parameters. In our work, we use four bins; 0, 0.1, 0.5, 0.8 leading to a $(4, 4)$ tensor where the bin closest to the target value (ex: $\dot{x}$)  on each row would contain one and the rest zero. Each selected bin is an anchor located at a specific distance away from the next expected value for the parameter considered. The classification function can be presented as $C(F_{k,i}) = C_{out}$ The regression function output would be a similarly shaped tensor $R_{out}$. It is essential for the loss function to consider the nature of both the classification as well as regression outputs of the network. The overall model of estimator is illustrated in Figure \ref{fig:LSTM_network}. Here intermediate tensor corresponds to the temporally aware feature maps $F_{k,i}$ of the $i^{th}$ object and the system has four similar but separate instances of the dense layers to handle each parameter and that finally results in outputs $C_{out}$ and $R_{out}$. In essence the network estimates how far an object would move from its current position over the next time step. The $x,y$ components capture motion along the image axes while the $h,w$ components correspond to the motion along the depth axis as well as morphological change of the object to some extent. 
% \par When training; the loss function is obtained as a weighted sum of the classification and regression losses. The classification loss $LOSS_{C}$ is a simple cross-entropy loss function. The regression loss takes into account the sparse nature of the ground truth regression tensor. Here $\odot$ denotes the Hadamard product of two tensors or matrices.
% $$
% LOSS_{C} = -\sum(C_{out_{true}} \odot log(C_{out_{pred}})) \eqno{(1)}
% $$
% $$
% LOSS_{R} = argmax(C_{out_{pred}}) \odot L_{Huber}(R_{out_{pred}},R_{out_{true}}) \eqno{(2)}
% $$
% $$
% LOSS_{Total} = \lambda_{C}*LOSS_{C} + \lambda_{R}*LOSS_{R} \eqno{(3)}
% $$

% \begin{figure*}[t]
% 	\vspace{-0.7cm}
% 	\centering
% 	\includegraphics[ width=\textwidth]{figs/tracker.png}
% 	\vspace{-0.5cm}
% 	\caption{Overview of the overall 2D tracking system}
% 	\label{fig:tracker}
% 	\vspace{0.4cm}
% \end{figure*}

% \subsection{Appearance similarity}

% One of the most challenging problems in this context is handling occlusions. Object tracking with the use of a Kalman filter or an LSTM network to handle spatial coherence among tracks has been a common approach. However, the uncertainty involved in the track prediction increases when tracks are exposed to prolonged occlusions. Hence it is required to re-identify occluded tracks. Deep SORT \cite{DeepSiam:deepSort} introduces the use of feature vectors to define an appearance descriptor for the purpose of track re-identification. Results presented in this work have proven this to be a successful approach. However, this comes with the additional burden of training a large network for the sole purpose of re-identification of a particular class of objects. Hence this approach is not versatile for multi-class object tracking or for online implementation. Our approach has the ability to handle multiple classes of objects and can be implemented online with ease.
% \par The approach implemented in this paper involves the use of a Siamese network to determine the appearance consistency of tracks. The Siamese networks described in the SiamFC \cite{DeepSiam:SiamFC, DeepSiam:endrep} and SiamMask \cite{DeepSiam:siammask} works have proven to be highly successful in single object tracking but have not been incorporated into multi-object tracking yet. It has been trained on ImageNet datasets for similarity learning and can operate online. Thus, it can give a class independent measure for appearance consistency of tracks and therefore would be ideal for track re-identification. The network discussed in SiamFC \cite{ DeepSiam:endrep} extracts the features of the exemplar image and search image to produce a cross correlation map whose peak position corresponds to the position of the object in the exemplar image within the search image. Similarly, we use a Siamese network to produce a similarity measure between two images of the same size by building up templates through a convolution neural network (a convolution function as in \cite{ DeepSiam:endrep} shown in template generation step through Figure \ref{fig:LSTM_association})
% \par The cross-correlation map produced by the Siamese network is passed through a similarity function to produce the similarity score, or more accurately an appearance cost. The similarity function in this context is defined as follows,
% $$
% Appearance \; Cost = A \exp(-k\ \sum f(x,y)) \eqno{(4)}
% $$
% where $f(x,y)$ is the cross correlation value at $x,y$ position in the cross correlation map and $A,k$ are tunable parameters.


% \subsection{Track Association}

% The track association is based on the association cost which depends on the appearance cost (from the Siamese network) as well as a distance metric. The distance metric is the measurement of how far the detection bounding box is from the bounding box of a track predicted by the LSTM. The distance metric between two bounding boxes is defined based on the IOU distance (intersection over union) between the bounding boxes. Let $ a_{i,j},c_{i,j},d_{i,j}$ represent the association cost, appearance cost and the distance metric between the $i^{th}$ detection and the $j^{th}$ track.
% $$ 
% a_{i,j} = 
% \begin{cases} 
% c_{i,j} \; if \; d_{i,j} < T \\
% K \; if \; d_{i,j} \geq T \\ 
% \end{cases}
% \eqno{(5)}
% $$
% where $K$ is the gating constant and $T$ is the gating threshold. Track association is treated as an assignment problem and is carried out using the Hungarian algorithm \cite{DeepSiam:hungarian} following very closely the approach discussed in Deep SORT \cite{DeepSiam:deepSort}.

% \subsection{Overall online tracking system}

% The Siamese network for similarity measurement is implemented in two stages. The first stage involves producing feature maps (templates) for detections in the current frame and the next stage involves producing cross correlation maps by convolving the detection templates with track templates and generating an appearance cost matrix between track, detection pairs in that frame. These two stages have been isolated to improve the efficiency of the approach.
% \par In a given frame, a crop of the bounding box corresponding to each detection is extracted. These crops are resized to 127x127 and passed through the first stage of the Siamese network to generate templates for each detection in that particular frame. These templates are passed through the second stage of the Siamese network along with the templates of tracks in order to generate a matrix of appearance costs. This cost matrix is gated according to the distance metric and subjected to the Hungarian algorithm to obtain track assignments for the detections.
% \par For matched track, detection pairs; the template of the track is updated using a rolling average between the track’s current template and the template of the detection which was matched to it,
% $$
% temp_{track} = \gamma * temp_{track} + (1 - \gamma) * temp_{det} \eqno{(6)}
% $$
% where $\gamma$ is the occluded percentage of the matched detection and defined as the maximum of the Intersection over Union values (IoU) between the detection bounding boxes and the bounding box of the matched detection which is one when fully occluded and zero when the object is fully visible. Therefore, when the matched detection is fully visible, it replaces the template of the track with the template of the matched detection and when the matched detection is fully occluded, it does not update the template of the track so as not to contaminate the template with the features from occlusions.
% \par Deletion of tracks and addition of new tracks is carried very similar to the approach carried out in the Deep SORT \cite{DeepSiam:deepSort} work.

% \subsection{Extensibility to BEV space}
% The seemingly simple but effective fact that ‘overlapping in BEV space projections cannot happen for the objects detected and predicted in 3D is exploited here through a constrained optimization problem. This work relates to the possible improvements that could be done on the system and detailed in \ref{chapter:appendix1}.

% \subsection{LSTM based data association for end to end trainability}

% \begin{figure*}[t]
% 	\centering
% 	\includegraphics[width=0.5\textwidth]{figs/lstm_associate.png}
% 	\vspace{-0.3cm}
% 	\caption{Association LSTM}
% 	\label{fig:LSTM_association}
% 	\vspace{0.5cm}
% \end{figure*}

% The multi object tracker network uses the Hungarian algorithm for data association where this algorithm is a definite setup having an algorithmic complexity of $O(n^3)$. However the system cannot be back propagated through this implementation due to the fact that Hungarian algorithm is not differentiable. There are approaches from probabilistic view points as in \cite{russel}  and with learning perspective as presented in \cite{DeepSiam:multitarget} for obtaining a data driven system. Several experiments were conducted with data association on MOT tracking dataset based on the methodology presented in [19]. The system developed is shown in Figure \ref{fig:LSTM_association} and was designed from scratch using tensorflow API. The system was designed initially to handle and check the repeated lengthy tracks in the dataset without the intervention of birth and death processes. Here the system is getting trained to build up a probability matrix $A_t$ which presents associations at time t. Thus $A_t^i=[p_{i,1},p_{i,2},p_{i,3},\ldots,p_{i,m},p_{i,m+1}]$ where  $p_{i,j}$ represents the probability of $i^{th}$  target being denoted by $j^{th}$ measurement out of m measurements for the frame (i.e. m detections).
% Here 
% $\sum_{j=1}^{m+1}p_{i,j}=1$ which is achieved by using softmax on the row.

% The excess column presented by the last probability shows the probability that none of measurements being matched for the respective track and this track will potentially be terminated in next stages of the process.
% The input $C_t\in R^{N\times M}$ is the matrix created through the second norm between the state vector $x_i$ of the target and the measurement having feature vector $z_j$.
% Therefore, $C_t^{i,j}=\ x_i-z_j^2$

% Negative log likelihood loss was used as the loss function for training. 


% \section{Panoptic Segmentation}
% Our work is concentrated to the assignment of a semantic label and an instance label for each pixel in an image using a novel approach of incorporating bipartite potentials to improve the segmentation accuracy.

% \subsection{Background: Conditional Random Fields}

% Conditional Random Fields (CRFs) are a class of statistical modeling method used for structured prediction. A CRF, used in the context of pixel-wise label prediction, models pixel labels as random variables that form a Markov Random Field (MRF) when conditioned upon the image. CRFs have primarily been used in computer vision for semantic image segmentation. In this setting, CRFs encourage the desirable properties of a good segmentation, such as the spatial consistency (e.g. spatially neighboring pixels should have the same label) and color consistency (e.g. a semantic segmentation boundary should correspond to a edge in the image) through various energy functions used in the formulation. A CRF formulation usually has energy terms arising from an imperfect classifier (sometimes known as the unary energy) and energy terms encouraging the consistency properties of the segmentation (sometimes known as the pairwise energy). Some semantic CRF models also include higher order energy terms to encourage higher order consistency properties such as consistency of the labeling within super-pixels~\cite{arnab_eccv_2016}.

% Once an appropriate energy function is formed, the optimal labeling is found as the labeling that minimizes the CRF energy (or equivalently, maximizes the probability). This is known as the inference of the CRF. The exact inference of a CRF with dense pairwise connections is intractable and hence approximate inference methods such as mean field variational inference has to be utilized to solve the CRF in reasonable time~\cite{densecrf}. For a detailed treatment of CRFs, the reader is referred to~\cite{Koller_book}. 

% \subsection{Bipartite CRFs}
% \label{sec:body}
% We propose a CRF formulation with bipartite random variables to capture interactions between semantic labels and instance labels. Inference of this CRF gives the jointly most probable semantic and instance segmentation (and therefore, the panoptic segmentation) for a given image. 

% For each pixel $i$, define a pair of discrete random variables $(X_i, Z_i)$ to denote its semantic label and the instance label, respectively. For each $i$, $X_i$ can take values in $\mathcal{L} = \{l_1, l_2, \dots, l_L\}$, where each $l_j$ is a semantic label and $L$ is the number of semantic labels (includes both stuff and thing classes). Therefore, $\mathcal{L} = \Lstuff \cup \Lthings$, where $\Lstuff$ is the set of stuff class labels and $\Lthings$ the set of thing class labels. Similarly, for each $i$, $Z_i$ can take values in $\mathcal{T} = \{\inst_0, \inst_1, \dots, \inst_{\Ninst} \}$, where $\Ninst$ is the number of instances detected in the image, and the label $\inst_0$ is reserved to represent the ``no instance'' case (the pixel belongs to a stuff class).  


% Let $\X = [X_1, X_2, \dots, X_N ]$ and $\Z = [Z_1, Z_2, \dots, Z_N
% ]$, where $N$ is the number of the pixels in the image. A joint assignment $(\x, \z)$ to these two random vectors $(\X, \Z)$ gives a unique semantic label and an instance label to each pixel $i$, and therefore represents a panoptic segmentation of the image. Note that, $\x \in \mathcal{L}^N$ and $\z \in \mathcal{T}^N$. In this work, we discuss the probability of such assignments and formulate the probability distribution function so that the ``good'' panoptic segmentation will have a high probability. We then perform inference on this formulation to find the assignment that maximizes the probability to obtain the best panoptic segmentation.

% The probability of a panoptic segmentation $(\x, \z)$, given the image $I$, can be modeled as a Gibbs distribution of the following form:
% \begin{equation}
% \label{eqn:prob}
% \Pr(\X = \x, \Z = \z|I) = \frac{1}{\mathcal{Z}(I)}\exp(-E(\x, \z|I)),
% \end{equation}
% where $\mathcal{Z}(I) = \sum_{(\x,\z)} \exp(-E(\x, \z|I))$, is a normalization constant, sometimes known as the partition function. The term $E(\x, \z|I)$ is known as the energy of the configuration $(\x, \z)$. Hereafter, we drop the conditioning on $I$ in the notation for brevity. The energy of our bipartite CRF is defined as follows:

% \begin{equation}
% \label{eqn:energy}
% \begin{split}
% E(\x, \z) =& \sum_i\phi(x_i) + \sum_{i < j}\Phi(x_i, x_j) \;+ \\
% & \sum_i\psi(z_i) + \sum_{i < j}\Psi(z_i, z_j) \; + \\
% & \sum_i\omega(x_i, z_i) + \sum_{i < j}\Omega(x_i, z_j),
% \end{split}
% \end{equation}
% where $x_i$ and $z_i$ are the elements of the vectors $\x$ and $\z$, respectively. The meaning of each term will be described in detail below. Note that, since a ``good'' panoptic segmentation should have a high probability, it should have a low energy. Various terms in Eq.~\eqref{eqn:energy} should therefore encourage a good panoptic segmentation by penalizing disagreements with our prior knowledge about a consistent panoptic segmentation. % Roughly speaking, the energy terms represent negative log probabilities. 

% \subsection{Semantic Component of the CRF}
% In the following, we discuss the first two term of the energy function in Eq.~\eqref{eqn:energy}. The first term encourages the semantic segmentation result to be consistent with the initial classifier.
% \begin{equation}
% \phi(X_i = x_i) = - \log(\Pro(X_i = x_i)),
% \end{equation}
% where $\Pro(.)$ is the classifier probability score for the semantic segmentation. 

% The second term in Eq.~\eqref{eqn:energy} encourages the smoothness of the semantic labeling:
% \begin{equation}
% \label{eq:similarity}
% \Phi(X_i = x_i, X_j = x_j) = \mu(x_i, x_j) \operatorname{Sim_\Phi}(i, j),
% \end{equation}
% where $\mu: \mathcal{L} \times \mathcal{L} \to \mathbb{R}$ is the label compatibility function, and $\operatorname{Sim_\Phi}(i, j)$ is a similarity measure between the pixels $i$ and $j$. This term penalizes assigning different labels to a pair of pixels that are ``similar". Following \cite{densecrf}, we use a mixture of Gaussians as the similarity measure. Therefore,
% \begin{equation}
% \label{eqn:kernels}
% \operatorname{Sim_\Phi}(i, j) = \sum_m w_{\Phi, m} \exp\left(-\frac{\|\vec{f}_i^{(m)} - \vec{f}_j^{(m)}\|^2}{2\sigma_{\Phi,m}^2}\right)
% \end{equation}
% where $\mathbf{f}_i$ is a feature vector for pixel $i$ containing information such as its spatial location and bilateral features (RGB + spatial coordinates). We use the same spatial and bilateral features used in~\cite{densecrf}.
% \subsection{Instance Component of the CRF}

% For the instance classification, we also assume the existence of an initial classifier, such as Mask R-CNN, that provides a confidence score for each instance at each pixel. Note that Mask R-CNN provides fixed-size instance segmentation predictions with respect to the bounding boxes of the detections. However, these predictions can be easily mapped to the full image by using bilinear interpolation and trivial coordinate transforms.

% In the following, we use $z_i \in \{\inst_0, \inst_1, \dots, \inst_\Ninst \}$, where $\Ninst$ is the number of instances detected in the image. The label $\inst_0$ is reserved for the special case where the pixel does not belong to an instance, i.e., it belongs to a stuff class.

% Similar to the semantic segmentation case, the third term in Eq.~\eqref{eqn:energy} encourages the panoptic segmentation to be consistent with the instance classifier probabilities $\Pro$:
% \begin{equation}
% \psi(Z_i = z_i) = - \log(\Pro(Z_i = z_i)).
% \end{equation}

% The fourth term in Eq.~\eqref{eqn:energy} encourages instance label consistency across the whole image by penalizing assigning different instance labels to similar pixels:
% \begin{equation}
% \Psi(Z_i = z_i, Z_j = z_j) = [z_i \neq z_j] \operatorname{Sim_\Psi}(i, j).
% \end{equation}
% The compatibility transform in this case is fixed to be $[z_i \neq z_j]$, where $[.]$ is the Iverson bracket. The similarity measure $\Sim_\Psi$ has a similar form to Eq.~\eqref{eqn:kernels}. %Intuitively, this term encourages \emph{similar} pixels to have the same instance label.

% \subsection{Cross Potentials in the CRF}
% An important contribution of this paper is the introduction of cross potentials between the semantic segmentation and instance segmentation. The semantic segmentation and the instance segmentation are highly related problems and therefore the solutions should agree: the semantic label at any pixel has to be compatible with the instance label at that pixel. For example, if the instance labeling says that the pixel $i$ belongs to an instance of a person class, the semantic label at pixel $i$ should also have the person label. If the initial classifier results for the instance segmentation and the semantic segmentation do not agree, one of them should correct itself depending on the interactions of other terms in the CRF.

% The first cross potential term (the fifth term in Eq.~\eqref{eqn:energy}), encourages instance label and the semantic label at a given pixel to agree:
% \begin{equation}
% \omega(X_i = x_i, Z_i = z_i) = f(x_i, \cl(z_i)).
% \end{equation}
% Here, $\cl(z_i)$ is the class label of the instance $z_i$ with $\inst_0$ mapped to a special class $\operatorname{null}$. Note that, for all valid instances, the class label can be obtained from the instance classifier (e.g. Mask R-CNN). The function $f(., .): (\mathcal{L}, \Lthings \cup \{\operatorname{{null}}\}) \to \mathbb{R}^+_0$, captures the cost of incompatibility and is defined as follows: 
% \begin{equation}
% \label{eqn:cross_compat}
% f(x_i, \cl(z_i)) = \begin{cases}
% 0,\;\;\text{if}\;x_i = \cl(z_i)\\
% 0,\;\;\text{if}\;x_i \in \mathcal{L}_{\text{stuff}}\;\text{and}\;\cl(z_i) = \operatorname{null}\\
% \eta(x_i, \cl(z_i)),\;\; \text{otherwise}.
% \end{cases}
% \end{equation}
% The above function covers three cases: 1) If the semantic label and the class label of the instance label match, there will be no penalty for such assignment since there is no incompatibility in this case. 2) If the semantic segmentation assigns a stuff label and the instance segmentation assigns $\inst_0$ label, there will be no penalty in that case either. 3) If the semantic label and the instance label mismatch, there will be a penalty with the magnitude decided by the function $\eta(., .): \Lthings \cup \{\operatorname{null}\} \times \Lthings \cup \{\operatorname{null}\} \to \mathbb{R}^+$. This function is learned from data as described in Section~\ref{sec:infer}.

% The last term in Eq.~\eqref{eqn:energy}, encourages the consistency of semantic label and the instance label among similar looking pixels and has the form:
% \begin{equation}
% \Omega(X_i = x_i, Z_j = z_j) = f(x_i, \cl(z_j))\; \operatorname{Sim_\Omega}(i, j),
% \end{equation}
% where each symbol has the meaning described above.


% \subsection{Inference and Parameter Optimization}
% \label{sec:infer}
% The best panoptic segmentation given the model described in Section~\ref{sec:body} is the assignment $(\x, \z)$ that maximizes the probability in Eq.~\eqref{eqn:prob}. However, since the graphical model used in BCRF has dense connections between the pixels, the exact inference is infeasible. We therefore use an approximate parallel mean field inference algorithm following~\cite{densecrf}.

% In this setting, the joint probability distribution is approximated by the product of marginal distributions:
% \begin{equation}
% \label{eq:q_approx}
% \Pr(\X=\x, \Z=\z) \approx \prod_i Q_i(x_i)\,R_i(z_i),
% \end{equation}
% where $Q_i(x_i) = \Pr(X_i = x_i)$ and $R_i(z_i) = \Pr(Z_i = z_i)$ are the marginal distributions. Out of all the distributions that can be written down in this factorized form, the closest distribution to the original joint distribution is found by minimizing the KL divergence~\cite{Koller_book, densecrf}. For our BCRF formulation, this results in the iterative algorithm detailed in Algorithm~\ref{alg:infer}.

% To make our model flexible, we deliberately include a number of parameters in the BCRF model, which we automatically learn from the training data. More specifically, the BCRF model has the following parameters:
% \begin{enumerate}
% 	\item Weight multipliers for different energy terms: each term in Eq.~\eqref{eqn:energy} is multiplied with a weight parameter, which decides the relative strength of the term. This parameterization helps learn the optimal combination of different energies in the CRF. For example, if the initial semantic segmentation model has better accuracy than the instance segmentation model, the $\phi$ unary energy might be weighted more than the $\psi$ unary energy.
	
% 	\item Parameters for similarity functions: Each similarity function $\Sim_X(i, j)$ of the form shown in Eq.~\eqref{eq:similarity} has its own parameters. These learn the relative strength of spatial and appearance consistency of the panoptic segmentation.
	
% 	\item Label compatibility matrices: The two functions $\mu(., .)$ and $\eta(., .)$ are initialized to have a zero cost for a pair identical labels and a fixed cost for any combination of two different labels. They are then given the freedom to automatically learn the relative penalty strengths for different label combinations.
% \end{enumerate}


% \subsection{BCRF in a Deep Network}
% In this section, we discuss how BCRF can be used in a deep network. In~\cite{Zhen_ICCV15_CRFRNN}, authors showed that, in the semantic segmentation setting, mean field inference of a CRF with Gaussian pairwise potentials can be formulated as a Recurrent Neural Network (RNN). Since our BCRF also uses an iterative mean field algorithm of similar nature, it is readily adaptable into the RNN based inference described in~\cite{Zhen_ICCV15_CRFRNN}. Therefore, BCRF can be a first-class citizen of a deep network performing panoptic segmentation. Importantly, this formulation allows automatic optimization of the BCRF parameters described in Section~\ref{sec:infer}, using backpropagation and a gradient descent algorithm such as stochastic gradient descent (SGD). This is a major advantage since it allows us to increase the number of parameters used in BCRF, and hence increase its flexibility, without adding to the burden of manual parameter optimization.

% In the current state-of-the-art methods, semantic segmentation and instance segmentation are solved with different network architectures with complimentary strengths. The BCRF formulation given a systematic way of combining these strengths in a probabilistic framework. Such an example usage of BCRF is shown in Figure~\ref{fig:bcrf_net}. The CNN feature extractor here can be a common backbone network such as ResNet-101 or ResNeXt. The semantic segmentation branch is usually a fully convolutional network that is capable of seeing a wide field of view, where as the instance segmentation branch is a region-proposal based network such as Mask R-CNN. The semantic segmentation branch's output is taken as the $\phi$ unary potential input to the BCRF, and instance segmentation branch's output as the $\psi$ unary potentials. In addition, the raw image is also fed into the BCRF to derive the similarity functions $\Sim_X(., .)$ using the pixel locations and the RGB values. 

% During the training of the network, in the forward pass, BCRF inference is performed using Algorithm~\ref{alg:infer}. A suitable loss function for panoptic segmentation can then be used at the output of the network. In the backward pass, differentials with respect to the loss function will be passed into the BCRF inference to optimize various parameters used in the BCRF model. Importantly, during the backward pass, after BCRF inference, the error differentials can be passed on to the semantic branch and the instance branch both to optimize their parameters, and subsequently, the feature extractor CNN's parameters. Therefore, the whole network, including the BCRF component, can be jointly trained.


